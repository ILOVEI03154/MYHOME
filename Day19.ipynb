{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n",
      "['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
      "['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'target']\n",
      "Index(['age', 'cp', 'trestbps', 'chol', 'restecg', 'thalach', 'oldpeak',\n",
      "       'slope', 'ca', 'thal', 'target', 'sex_0', 'sex_1', 'fbs_0', 'fbs_1',\n",
      "       'exang_0', 'exang_1'],\n",
      "      dtype='object')\n",
      "--- 1. 默认参数随机森林 (训练集 -> 测试集) ---\n",
      "训练与预测耗时: 0.2282 秒\n",
      "\n",
      "默认随机森林 在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        29\n",
      "           1       0.88      0.88      0.88        32\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "默认随机森林 在测试集上的混淆矩阵：\n",
      "[[25  4]\n",
      " [ 4 28]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd    #用于数据处理和分析，可处理表格数据。\n",
    "import numpy as np     #用于数值计算，提供了高效的数组操作。\n",
    "import matplotlib.pyplot as plt    #用于绘制各种类型的图表\n",
    "import seaborn as sns   #基于matplotlib的高级绘图库，能绘制更美观的统计图形。\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    " # 设置中文字体（解决中文显示问题）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # Windows系统常用黑体字体\n",
    "plt.rcParams['axes.unicode_minus'] = False    # 正常显示负号\n",
    "data = pd.read_csv('heart.csv')    #读取数据\n",
    "print(data.columns)    #'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', \n",
    "# 'restecg', 'thalach','exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "#提取连续特征值\n",
    "continuous_features = ['age','trestbps', 'chol', 'thalach','oldpeak']\n",
    "print(continuous_features)    #打印出连续特征值的列名\n",
    "#提取离散特征值\n",
    "discrete_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal','target']\n",
    "print(discrete_features)    #打印出离散特征值的列名\n",
    "\n",
    "#使用映射字典进行转换\n",
    "mapping_dict = {\n",
    "    'cp':{0:0,1:1,2:2,3:3},\n",
    "    'restecg':{0:0,1:1,2:2},\n",
    "    'slope':{0:0,1:1,2:2},\n",
    "    'thal':{0:0,1:1,2:2,3:3},\n",
    "    'ca':{0:0,1:1,2:2,3:3,4:4}\n",
    "}\n",
    "for feature, mapping_dict in mapping_dict.items():    #遍历映射字典\n",
    "    data[feature] = data[feature].map(mapping_dict)    #将映射字典中的值替换为原数据中的值\n",
    "\n",
    "#对离散特征值进行独热编码\n",
    "data = pd.get_dummies(data, columns=['sex', 'fbs','exang'])    #对离散特征值进行独热编码\n",
    "print(data.columns)    #打印出数据的列名\n",
    "data2 = pd.read_csv(\"heart.csv\")    #读取数据\n",
    "list_final = []    #新建一个空列表，用于存放独热编码后新增的特征名\n",
    "for i in data.columns:    #遍历数据的列名\n",
    "    if i not in data2.columns:    #如果列名不在原数据的列名中\n",
    "        list_final.append(i)    #将列名添加到列表中\n",
    "for i in list_final:    #遍历列表中的列名\n",
    "    data[i] = data[i].astype(int)    #将列名转换为int类型\n",
    "#划分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split    #导入train_test_split函数\n",
    "X = data.drop(['target'], axis=1)    #特征，axis=1表示按列删除\n",
    "y = data['target']    #标签\n",
    "#按照8:2划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)    #80%训练集，20%测试集\n",
    "# print(X_train.shape)    #打印出训练集的形状\n",
    "# print(X_test.shape)    #打印出测试集的形状\n",
    "from sklearn.ensemble import RandomForestClassifier #随机森林分类器\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score # 用于评估分类器性能的指标\n",
    "from sklearn.metrics import classification_report, confusion_matrix #用于生成分类报告和混淆矩阵\n",
    "import warnings #用于忽略警告信息\n",
    "warnings.filterwarnings(\"ignore\") # 忽略所有警告信息\n",
    "# --- 1. 默认参数的随机森林 ---\n",
    "# 评估基准模型，这里确实不需要验证集\n",
    "print(\"--- 1. 默认参数随机森林 (训练集 -> 测试集) ---\")\n",
    "import time # 这里介绍一个新的库，time库，主要用于时间相关的操作，因为调参需要很长时间，记录下会帮助后人知道大概的时长\n",
    "start_time = time.time() # 记录开始时间\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train) # 在训练集上训练\n",
    "rf_pred = rf_model.predict(X_test) # 在测试集上预测\n",
    "end_time = time.time() # 记录结束时间\n",
    "\n",
    "print(f\"训练与预测耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(\"\\n默认随机森林 在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "print(\"默认随机森林 在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过去电脑性能比较差，特征数目太多计算起来很慢。同时特征中可能存在很多冗余特征干扰解释性、存在噪声特征干扰精度。\n",
    "\n",
    "所以在面对高维特征的时候常常需要引入特征降维，我们之前课程中的项目的特征也就小几十个，不太需要做降维，对于某些特征较多的数据，如基因数据、微生物数据、传感器数据等，特征较多，所以会考虑特征降维。\n",
    "\n",
    "特征降维一般有2种策略：\n",
    "1. 特征筛选：从n个特征中筛选出m个特征，比如方差筛选，剔除方差过小的特征；利用皮尔逊相关系数筛选；lasso筛选（lasso自带的系数可以理解为重要性）、利用树模型自带的重要性、shap重要性等筛选；特征递归方法\n",
    "2. 特征组合：从n个特征中组合出m个特征，如pca等\n",
    "\n",
    "今天这节先说一下特征筛选\n",
    "\n",
    "特征筛选\n",
    "## 方差筛选\n",
    "\n",
    "方差筛选是一种简单而有效的特征筛选方法。它的核心逻辑是：特征的方差反映了数据的变化程度，方差很小的特征几乎没有变化，对模型的预测帮助不大。比如，一个特征的值在所有样本中几乎都一样（方差接近0），那么它对区分不同类别或预测结果几乎没有贡献。因此，方差筛选会设定一个方差阈值，剔除方差低于这个阈值的特征，保留那些变化较大的特征，从而减少特征数量，提高模型效率。\n",
    "\n",
    "这种方法特别适合处理高维数据，能快速去掉不重要的特征，但它不考虑特征与目标变量之间的关系，可能会误删一些低方差但有意义的特征。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---方差筛选（Variance Threshold）---\n",
      "方差筛选后保留的特征数量: 16\n",
      "保留的特征: ['age', 'cp', 'trestbps', 'chol', 'restecg', 'thalach', 'oldpeak', 'slope', 'ca', 'thal', 'sex_0', 'sex_1', 'fbs_0', 'fbs_1', 'exang_0', 'exang_1']\n",
      "训练与预测耗时: 0.1510 秒\n",
      "\n",
      "方差筛选后随机森林在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        29\n",
      "           1       0.88      0.88      0.88        32\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "方差筛选后随机森林在测试集上的混淆矩阵：\n",
      "[[25  4]\n",
      " [ 4 28]]\n"
     ]
    }
   ],
   "source": [
    "print(\"---方差筛选（Variance Threshold）---\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "X_train_var = selector.fit_transform(X_train)\n",
    "\n",
    "X_test_var = selector.transform(X_test)\n",
    "\n",
    "selected_features_var = X_train.columns[selector.get_support()].tolist()\n",
    "\n",
    "print(f\"方差筛选后保留的特征数量: {len(selected_features_var)}\")\n",
    "print(f\"保留的特征: {selected_features_var}\")\n",
    "\n",
    "rf_model_var = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_model_var.fit(X_train_var, y_train)\n",
    "\n",
    "rf_pred_var = rf_model_var.predict(X_test_var)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"训练与预测耗时: {end_time - start_time:.4f} 秒\")\n",
    "\n",
    "print(\"\\n方差筛选后随机森林在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred_var))\n",
    "\n",
    "print(\"方差筛选后随机森林在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 皮尔逊相关系数筛选\n",
    "\n",
    "皮尔逊相关系数筛选是一种基于特征与目标变量之间相关性的特征选择方法。它的核心逻辑是：计算每个特征与目标变量之间的相关系数（范围在-1到1之间，值越大表示正相关越强，值越小表示负相关越强，接近0表示几乎无关），然后根据相关系数的绝对值大小，选择与目标变量相关性较高的特征，剔除相关性较低的特征。这种方法适用于目标变量是连续型的情况（如果是分类问题，可以先对目标变量编码）。通过皮尔逊相关系数筛选，我们可以保留那些对预测目标最有帮助的特征，减少无关或冗余特征的干扰。\n",
    "\n",
    "皮尔逊相关系数筛选法是一种基于变量相关性的经典特征选择技术，常用于处理目标变量为连续型的场景。若面对分类问题，通常需要先对目标变量进行编码处理，将其转化为数值型数据后再开展分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 皮尔逊相关系数筛选 ---\n",
      "皮尔逊相关系数筛选后保留的特征数量: 10\n",
      "保留的特征: ['cp', 'thalach', 'oldpeak', 'slope', 'ca', 'thal', 'sex_0', 'sex_1', 'exang_0', 'exang_1']\n",
      "训练与预测耗时: 0.1461 秒\n",
      "\n",
      "皮尔逊相关系数筛选后随机森林在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        29\n",
      "           1       0.81      0.81      0.81        32\n",
      "\n",
      "    accuracy                           0.80        61\n",
      "   macro avg       0.80      0.80      0.80        61\n",
      "weighted avg       0.80      0.80      0.80        61\n",
      "\n",
      "皮尔逊相关系数筛选后随机森林在测试集上的混淆矩阵：\n",
      "[[23  6]\n",
      " [ 6 26]]\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 皮尔逊相关系数筛选 ---\")\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 计算特征与目标变量的相关性，选择前k个特征（这里设为10个，可调整）\n",
    "# 注意：皮尔逊相关系数通常用于回归问题（连续型目标变量），但如果目标是分类问题，可以用f_classif\n",
    "k = 10\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_train_corr = selector.fit_transform(X_train, y_train)\n",
    "X_test_corr = selector.transform(X_test)\n",
    "\n",
    "# 获取筛选后的特征名\n",
    "selected_features_corr = X_train.columns[selector.get_support()].tolist()\n",
    "print(f\"皮尔逊相关系数筛选后保留的特征数量: {len(selected_features_corr)}\")\n",
    "print(f\"保留的特征: {selected_features_corr}\")\n",
    "\n",
    "# 训练随机森林模型\n",
    "rf_model_corr = RandomForestClassifier(random_state=42)\n",
    "rf_model_corr.fit(X_train_corr, y_train)\n",
    "rf_pred_corr = rf_model_corr.predict(X_test_corr)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"训练与预测耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(\"\\n皮尔逊相关系数筛选后随机森林在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred_corr))\n",
    "print(\"皮尔逊相关系数筛选后随机森林在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lasso筛选（基于L1正则化）\n",
    "\n",
    "Lasso回归（Least Absolute Shrinkage and Selection Operator）是一种结合特征选择和模型训练的方法。它的核心逻辑是：在进行线性回归的同时，通过引入L1正则化项（即惩罚项），强制将一些不重要特征的回归系数压缩到0，从而实现特征筛选。换句话说，Lasso会自动“挑选”对预测目标有贡献的特征（系数不为0），而剔除无关或冗余的特征（系数为0）。这种方法特别适合处理高维数据，可以减少特征数量，提高模型的解释性和计算效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Lasso筛选 (L1正则化) ---\n",
      "Lasso筛选后保留的特征数量: 12\n",
      "保留的特征: ['age', 'cp', 'trestbps', 'chol', 'restecg', 'thalach', 'oldpeak', 'slope', 'ca', 'thal', 'sex_0', 'exang_0']\n",
      "训练与预测耗时: 0.1568 秒\n",
      "\n",
      "Lasso筛选后随机森林在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        29\n",
      "           1       0.84      0.84      0.84        32\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.84      0.84      0.84        61\n",
      "weighted avg       0.84      0.84      0.84        61\n",
      "\n",
      "Lasso筛选后随机森林在测试集上的混淆矩阵：\n",
      "[[24  5]\n",
      " [ 5 27]]\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Lasso筛选 (L1正则化) ---\")\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 使用Lasso回归进行特征筛选\n",
    "lasso = Lasso(alpha=0.01, random_state=42)  # alpha值可调整\n",
    "selector = SelectFromModel(lasso)\n",
    "selector.fit(X_train, y_train)\n",
    "X_train_lasso = selector.transform(X_train)\n",
    "X_test_lasso = selector.transform(X_test)\n",
    "\n",
    "# 获取筛选后的特征名\n",
    "selected_features_lasso = X_train.columns[selector.get_support()].tolist()\n",
    "print(f\"Lasso筛选后保留的特征数量: {len(selected_features_lasso)}\")\n",
    "print(f\"保留的特征: {selected_features_lasso}\")\n",
    "\n",
    "# 训练随机森林模型\n",
    "rf_model_lasso = RandomForestClassifier(random_state=42)\n",
    "rf_model_lasso.fit(X_train_lasso, y_train)\n",
    "rf_pred_lasso = rf_model_lasso.predict(X_test_lasso)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"训练与预测耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(\"\\nLasso筛选后随机森林在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred_lasso))\n",
    "print(\"Lasso筛选后随机森林在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred_lasso))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 树模型自带的重要性筛选 ---\n",
      "树模型重要性筛选后保留的特征数量: 8\n",
      "保留的特征: ['age', 'cp', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca', 'thal']\n",
      "训练与预测耗时: 0.2832 秒\n",
      "\n",
      "树模型重要性筛选后随机森林在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82        29\n",
      "           1       0.82      0.88      0.85        32\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.84      0.83      0.83        61\n",
      "weighted avg       0.84      0.84      0.84        61\n",
      "\n",
      "树模型重要性筛选后随机森林在测试集上的混淆矩阵：\n",
      "[[23  6]\n",
      " [ 4 28]]\n"
     ]
    }
   ],
   "source": [
    "#树模型重要性\n",
    "print(\"--- 树模型自带的重要性筛选 ---\")\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 使用随机森林的特征重要性进行筛选\n",
    "rf_selector = RandomForestClassifier(random_state=42)\n",
    "rf_selector.fit(X_train, y_train)\n",
    "selector = SelectFromModel(rf_selector, threshold=\"mean\")  # 阈值设为平均重要性，可调整\n",
    "X_train_rf = selector.transform(X_train)\n",
    "X_test_rf = selector.transform(X_test)\n",
    "\n",
    "# 获取筛选后的特征名\n",
    "selected_features_rf = X_train.columns[selector.get_support()].tolist()\n",
    "print(f\"树模型重要性筛选后保留的特征数量: {len(selected_features_rf)}\")\n",
    "print(f\"保留的特征: {selected_features_rf}\")\n",
    "\n",
    "# 训练随机森林模型\n",
    "rf_model_rf = RandomForestClassifier(random_state=42)\n",
    "rf_model_rf.fit(X_train_rf, y_train)\n",
    "rf_pred_rf = rf_model_rf.predict(X_test_rf)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"训练与预测耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(\"\\n树模型重要性筛选后随机森林在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred_rf))\n",
    "print(\"树模型重要性筛选后随机森林在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SHAP重要性筛选 ---\n",
      "SHAP重要性筛选后保留的特征数量: 2\n",
      "保留的特征: ['age', 'cp']\n",
      "训练与预测耗时: 0.3895 秒\n",
      "\n",
      "SHAP重要性筛选后随机森林在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75        29\n",
      "           1       0.83      0.59      0.69        32\n",
      "\n",
      "    accuracy                           0.72        61\n",
      "   macro avg       0.74      0.73      0.72        61\n",
      "weighted avg       0.75      0.72      0.72        61\n",
      "\n",
      "SHAP重要性筛选后随机森林在测试集上的混淆矩阵：\n",
      "[[25  4]\n",
      " [13 19]]\n"
     ]
    }
   ],
   "source": [
    "#shap重要性筛选\n",
    "print(\"--- SHAP重要性筛选 ---\")\n",
    "import shap\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 使用随机森林模型计算SHAP值\n",
    "rf_shap = RandomForestClassifier(random_state=42)\n",
    "rf_shap.fit(X_train, y_train)\n",
    "explainer = shap.TreeExplainer(rf_shap)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# 计算每个特征的平均SHAP值（取绝对值的平均）\n",
    "mean_shap = np.abs(shap_values[1]).mean(axis=0)  # shap_values[1]对应正类\n",
    "k = 10  # 选择前10个特征，可调整\n",
    "top_k_indices = np.argsort(mean_shap)[-k:]\n",
    "X_train_shap = X_train.iloc[:, top_k_indices]\n",
    "X_test_shap = X_test.iloc[:, top_k_indices]\n",
    "\n",
    "# 获取筛选后的特征名\n",
    "selected_features_shap = X_train.columns[top_k_indices].tolist()\n",
    "print(f\"SHAP重要性筛选后保留的特征数量: {len(selected_features_shap)}\")\n",
    "print(f\"保留的特征: {selected_features_shap}\")\n",
    "\n",
    "# 训练随机森林模型\n",
    "rf_model_shap = RandomForestClassifier(random_state=42)\n",
    "rf_model_shap.fit(X_train_shap, y_train)\n",
    "rf_pred_shap = rf_model_shap.predict(X_test_shap)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"训练与预测耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(\"\\nSHAP重要性筛选后随机森林在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred_shap))\n",
    "print(\"SHAP重要性筛选后随机森林在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred_shap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 递归特征消除 (RFE) ---\n",
      "RFE筛选后保留的特征数量: 10\n",
      "保留的特征: ['age', 'cp', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca', 'thal', 'exang_0', 'exang_1']\n",
      "训练与预测耗时: 1.1288 秒\n",
      "\n",
      "RFE筛选后随机森林在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82        29\n",
      "           1       0.82      0.88      0.85        32\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.84      0.83      0.83        61\n",
      "weighted avg       0.84      0.84      0.84        61\n",
      "\n",
      "RFE筛选后随机森林在测试集上的混淆矩阵：\n",
      "[[23  6]\n",
      " [ 4 28]]\n"
     ]
    }
   ],
   "source": [
    "#递归特征消除RFE\n",
    "\n",
    "\"\"\"\n",
    "递归特征消除是一种特征选择方法，广泛用于机器学习中，特别是在分类和回归问题中，\n",
    "用于从一组特征中筛选出对模型性能贡献最大的子集。RFE的核心思想是通过递归地移除最不重要的特征，\n",
    "逐步缩小特征集，直到达到预设的特征数量或满足其他停止条件。\n",
    "\"\"\"\n",
    "print(\"--- 递归特征消除 (RFE) ---\")\n",
    "from sklearn.feature_selection import RFE\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 使用随机森林作为基础模型进行RFE\n",
    "base_model = RandomForestClassifier(random_state=42)\n",
    "rfe = RFE(base_model, n_features_to_select=10)  # 选择10个特征，可调整\n",
    "rfe.fit(X_train, y_train)\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# 获取筛选后的特征名\n",
    "selected_features_rfe = X_train.columns[rfe.support_].tolist()\n",
    "print(f\"RFE筛选后保留的特征数量: {len(selected_features_rfe)}\")\n",
    "print(f\"保留的特征: {selected_features_rfe}\")\n",
    "\n",
    "# 训练随机森林模型\n",
    "rf_model_rfe = RandomForestClassifier(random_state=42)\n",
    "rf_model_rfe.fit(X_train_rfe, y_train)\n",
    "rf_pred_rfe = rf_model_rfe.predict(X_test_rfe)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"训练与预测耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(\"\\nRFE筛选后随机森林在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred_rfe))\n",
    "print(\"RFE筛选后随机森林在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred_rfe))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
